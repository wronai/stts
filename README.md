# ğŸ™ï¸ stts - Universal Voice Shell

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://python.org)
[![Node.js Version](https://img.shields.io/badge/node.js-18+-green.svg)](https://nodejs.org)
[![Platform](https://img.shields.io/badge/platform-Linux%20%7C%20macOS%20%7C%20Windows-lightgrey.svg)](https://github.com/wronai/stts)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://github.com/wronai/stts)

## ğŸ“‹ Menu

- [ğŸš€ Szybki start](#szybki-start)
- [âš™ï¸ Konfiguracja](#konfiguracja)
- [âœ¨ Funkcje](#-funkcje)
- [ğŸ“Š Wymagania sprzÄ™towe](#-wymagania-sprzÄ™towe)
- [ğŸ’» UÅ¼ycie](#-uÅ¼ycie)
- [ğŸ”§ Providery](#-providery)
- [ğŸ“ Raspberry Pi](#-raspberry-pi)
- [ğŸ› Troubleshooting](#-troubleshooting)
- [ğŸ“ Struktura](#-struktura)
- [ğŸ“š Dokumentacja](#-dokumentacja)
- [ğŸ”— PowiÄ…zane projekty](#-powiÄ…zane-projekty)

Repo zostaÅ‚o podzielone na **dwa niezaleÅ¼ne projekty**:

- **`python/`** - wersja Python
- **`nodejs/`** - wersja Node.js (ESM)

KaÅ¼dy folder ma wÅ‚asne:

- `README.md`
- `Makefile`
- `Dockerfile`
- testy Docker (bez mikrofonu)

## Szybki start


uÅ¼ycie STT i TTS w komendzie shell:

```bash
#tylko STT
./stts git commit -m "{STT}"
# razem z TTS 
./stts git commit -m "{STT}" | ./stts --tts-stdin
# z TTS espeak angielski
./stts git commit -m "{STT}" | ./stts --tts-stdin --tts-provider espeak --tts-voice en
# z konfiguracjÄ… TTS lepszej jakosci
./stts git commit -m "{STT}" | ./stts --tts-provider piper --tts-voice en_US-amy-medium --tts-stdin
# z konfiguracjÄ… TTS polski lepszej jakosci
./stts git commit -m "{STT}" | ./stts --tts-provider piper --tts-voice pl_PL-gosia-medium --tts-stdin
```

```bash
# GPU + szybki start
STTS_GPU_ENABLED=1 STTS_FAST_START=1 ./stts

# CPU-only z mniejszym modelem
./stts --init whisper_cpp:tiny
```

Uruchamianie komend shell nawet z bÅ‚Ä™dami fonetycznymi za pomocÄ… nlp2cmd:
```bash
./stts nlp2cmd -r "{STT}" --auto-confirm | ./stts --tts-stdin
```

output
```bash
[13:14:01] ğŸ¤ MÃ³w (max 5s, VAD)... âœ… VAD stop (3.4s / 3.7s)
ğŸ” audio: 3.4s, rms=-37.4dBFS
[13:14:05] ğŸ”„ Rozpoznawanie... âœ… "lista folderÃ³w" (5.5s)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸš€ Run Mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ lista folderÃ³w                                                                                                                                                                                                                             â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Generating command...
Detected: shell/list

$ ls -la .
  total 108
  drwxrwxr-x 10 tom tom  4096 Jan 24 13:13 .
  drwxrwxr-x 31 tom tom  4096 Jan 24 09:33 ..
  -rw-r--r--  1 tom tom  1512 Jan 24 12:12 .env.example
  drwxrwxr-x  7 tom tom  4096 Jan 24 13:06 .git
  -rw-r--r--  1 tom tom  1664 Jan 24 10:34 .gitignore
  drwxrwxr-x  3 tom tom  4096 Jan 24 12:29 .idea
  -rw-rw-r--  1 tom tom 11357 Jan 24 09:33 LICENSE
  -rw-r--r--  1 tom tom  4658 Jan 24 12:21 Makefile
  -rw-rw-r--  1 tom tom 12421 Jan 24 13:13 README.md
  -rw-r--r--  1 tom tom     7 Jan 24 13:05 VERSION
  -rw-r--r--  1 tom tom  2291 Jan 24 12:20 bump_version.py
  drwxrwxr-x  2 tom tom  4096 Jan 24 13:05 dist
  drwxrwxr-x  5 tom tom  4096 Jan 24 10:38 nodejs
  -rw-r--r--  1 tom tom   300 Jan 24 13:05 package.json
  -rw-r--r--  1 tom tom   514 Jan 24 13:05 pyproject.toml
  drwxr-xr-x  7 tom tom  4096 Jan 24 10:43 python
  drwxr-xr-x  2 tom tom  4096 Jan 24 10:57 scripts
  -rwxr-xr-x  1 tom tom   573 Jan 24 10:11 stts
  drwxrwxr-x  2 tom tom  4096 Jan 24 13:05 stts.egg-info
  -rwxr-xr-x  1 tom tom   462 Jan 24 10:11 stts.mjs
  drwxrwxr-x  5 tom tom  4096 Jan 24 10:56 venv
âœ“ Command completed in 9.1ms
[stts] TTS: provider=piper voice=en_US-amy-medium
```

**Uwaga:** DomyÅ›lnie output komend moÅ¼e byÄ‡ buforowany (w zaleÅ¼noÅ›ci od trybu). JeÅ›li chcesz **zawsze widzieÄ‡ output na Å¼ywo**, uÅ¼yj `--stream` albo ustaw `STTS_STREAM=1`.

```bash
./stts git commit -m "{STT}" | ./stts --tts-stdin
[12:23:19] ğŸ¤ MÃ³w (max 5s, VAD)... âœ… VAD stop (4.4s / 4.6s)
ğŸ” audio: 4.4s, rms=-44.5dBFS
[12:23:24] ğŸ”„ Rozpoznawanie... âœ… "Aktualizuj dokumentacjÄ™." (5.7s)
On branch main
Your branch is up to date with 'origin/main'.

nothing to commit, working tree clean

[stts] TTS: provider=piper voice=pl_PL-gosia-medium
```
## Konfiguracja

```bash
# Python
cd python
cp .env.example .env
./stts --setup
./stts

# Node.js
cd nodejs
cp .env.example .env
./stts.mjs --setup
./stts.mjs
```

Szybki setup (bez interakcji, Python):

```bash
./stts --init whisper_cpp:tiny
```


## .env (ustawienia / linki / domyÅ›lne wartoÅ›ci)

W repo jest `/.env.example` (oraz osobne `python/.env.example`, `nodejs/.env.example`).
Skrypty automatycznie wczytujÄ… `.env`.

NajwaÅ¼niejsze zmienne:

- `STTS_CONFIG_DIR` - katalog na modele/cache (rÃ³wnieÅ¼ dla Docker volume)
- `STTS_TIMEOUT` - czas nagrywania STT (sekundy), domyÅ›lnie `5`
- `STTS_NLP2CMD_ENABLED=1` - wÅ‚Ä…cza NL â†’ komenda przez `nlp2cmd`
- `STTS_NLP2CMD_ARGS=-r` - tryb jak w przykÅ‚adach: `nlp2cmd -r "PokaÅ¼ uÅ¼ytkownikÃ³w"`
- `STTS_NLP2CMD_CONFIRM=1` - pytaj o potwierdzenie przed wykonaniem
- `STTS_PIPER_AUTO_INSTALL=1` - auto-instalacja piper binarki (Python)
- `STTS_PIPER_AUTO_DOWNLOAD=1` - auto-download modelu gÅ‚osu piper (Python)
- `STTS_STREAM=1` - strumieniuj output komend (bez buforowania)
- `STTS_FAST_START=1` - szybszy start (mniej detekcji sprzÄ™tu)
- `STTS_STT_GPU_LAYERS=35` - whisper.cpp: liczba warstw na GPU (`-ngl`, wymaga build GPU)
- `STTS_GPU_ENABLED=1` - wymuÅ› budowÄ™ whisper.cpp z CUDA przy instalacji
- `STTS_PIPER_RELEASE_TAG=2023.11.14-2` - wersja piper do pobrania
- `STTS_PIPER_VOICE_VERSION=v1.0.0` - wersja gÅ‚osÃ³w piper do pobrania

## NLP2CMD (Natural Language â†’ komendy)

W wersji Python i Node moÅ¼esz:

- wpisaÄ‡: `nlp PokaÅ¼ uÅ¼ytkownikÃ³w`
- albo uÅ¼yÄ‡ STT: ENTER â†’ powiedz tekst â†’ skrypt odpali `nlp2cmd` i zapyta o potwierdzenie

Instalacja `nlp2cmd`:

```bash
cd python && make pip-nlp2cmd
```

## TTS: szybki setup + autodiagnostyka (Python)

JeÅ›li "TTS nie dziaÅ‚a" (cisza), najczÄ™stsze przyczyny:

- brak binarki providera (`espeak` / `piper`)
- dla `piper`: brak modelu `*.onnx` **i** `*.onnx.json`
- brak odtwarzacza audio (`paplay` / `aplay` / `play`) dla `piper`

### Test TTS (bez STT)

```bash
./stts --tts-test "Test syntezatora mowy"
```

### Setup: espeak (Linux)

```bash
make tts-setup-espeak
```

### Setup: piper (Linux, auto-download)

```bash
make tts-setup-piper
```

### Piper: automatyczny install + auto-download w runtime

Wersja Python potrafi automatycznie:

- pobraÄ‡ binarkÄ™ `piper` do `~/.config/stts-python/bin/`
- pobraÄ‡ model i config gÅ‚osu do `~/.config/stts-python/models/piper/`

RÄ™cznie (CLI):

```bash
./stts --install-piper
./stts --download-piper-voice pl_PL-gosia-medium
./stts --tts-provider piper --tts-voice pl_PL-gosia-medium
./stts --tts-test "CzeÅ›Ä‡, to dziaÅ‚a."
```

## Testy w Docker (bez dostÄ™pu do audio)

Testy dziaÅ‚ajÄ… przez **symulacjÄ™ wypowiedzi usera**:

1. Generujemy prÃ³bki audio do plikÃ³w `samples/*.wav`
2. Do kaÅ¼dej prÃ³bki zapisujemy transkrypt w `samples/*.wav.txt`
3. W testach ustawiamy `STTS_MOCK_STT=1` i uruchamiamy `--stt-file ...`

```bash
# wszystkie platformy
make test-docker

# albo osobno
make docker-test-python
make docker-test-nodejs
```

Testy Docker montujÄ… cache/config jako volume (Å¼eby nie pobieraÄ‡ modeli za kaÅ¼dym razem).
DomyÅ›lne katalogi cache:

- `CACHE_DIR_PYTHON=~/.config/stts-python`
- `CACHE_DIR_NODEJS=~/.config/stts-nodejs`

MoÅ¼esz je nadpisaÄ‡:

```bash
make test-docker CACHE_DIR_PYTHON=/tmp/stts-python-cache CACHE_DIR_NODEJS=/tmp/stts-nodejs-cache
```

Alternatywnie (wrapper shell):

```bash
bash scripts/test_docker_all.sh --cache-python /tmp/stts-python-cache --cache-nodejs /tmp/stts-nodejs-cache
```

## E2E examples

PoniÅ¼ej sÄ… przykÅ‚ady end-to-end, ktÃ³re da siÄ™ uruchomiÄ‡ lokalnie oraz w CI.

### E2E offline (Docker, bez mikrofonu)

To jest najbardziej powtarzalne (deterministyczne):

- generujemy `samples/*.wav`
- zapisujemy oczekiwany tekst do `samples/*.wav.txt`
- ustawiamy `STTS_MOCK_STT=1` (STT czyta sidecar zamiast odpalaÄ‡ model)

```bash
make docker-test-python
make docker-test-nodejs
```

### E2E offline (placeholder / captions loop)

Tryb `--stt-stream-shell` pozwala odpalaÄ‡ w pÄ™tli komendÄ™-szablon z podstawieniem `{STT}` / `{STT_STREAM}`.
W CI/Docker moÅ¼esz to uruchomiÄ‡ jednorazowo z `--stt-file`:

```bash
STTS_MOCK_STT=1 ./stts --stt-file python/samples/cmd_echo_hello.wav \
  --stt-stream-shell --cmd "echo '{STT_STREAM}'" --dry-run
```

### E2E online (Deepgram, STT provider=deepgram)

Wersja Python ma provider `deepgram` (REST, transkrypcja z pliku WAV).

Wymaga:

- `STTS_DEEPGRAM_KEY=...`

PrzykÅ‚ad (tylko transkrypcja):

```bash
STTS_DEEPGRAM_KEY=sk-... STTS_STT_PROVIDER=deepgram ./stts --stt-file python/samples/cmd_ls.wav --stt-only
```

Model moÅ¼na ustawiÄ‡:

```bash
STTS_DEEPGRAM_KEY=sk-... STTS_STT_PROVIDER=deepgram STTS_DEEPGRAM_MODEL=nova-2 ./stts --stt-file python/samples/cmd_ls.wav --stt-only
```

## âœ¨ Funkcje

- **Auto-detekcja sprzÄ™tu** - sprawdza RAM, GPU, CPU i rekomenduje odpowiedni model
- **WybÃ³r STT** - whisper.cpp, faster-whisper, vosk, Google Speech
- **WybÃ³r TTS** - espeak, piper (neural), system TTS
- **Auto-pobieranie** - modele pobierane automatycznie
- **Cross-platform** - Linux, macOS, Windows, Raspberry Pi
- **Zero konfiguracji** - interaktywny setup przy pierwszym uruchomieniu
- **ğŸ® GPU Acceleration** - automatyczna kompilacja z CUDA (NVIDIA)
- **ğŸ”§ Text Normalization** - korekta bÅ‚Ä™dÃ³w STT dla komend shell
- **âš¡ Fast Start** - szybkie uruchamianie z lazy initialization

## ğŸ® GPU Acceleration (CUDA)

JeÅ›li masz kartÄ™ NVIDIA z CUDA toolkit, whisper.cpp zostanie automatycznie skompilowany z GPU:

```bash
# Auto-detect (domyÅ›lne)
./stts --setup

# WymuÅ› GPU
STTS_GPU_ENABLED=1 ./stts --setup

# WymuÅ› CPU-only
STTS_GPU_ENABLED=0 ./stts --setup
```

Konfiguracja GPU layers (ile warstw modelu na GPU):

```bash
# Wszystkie warstwy na GPU (domyÅ›lne)
STTS_GPU_LAYERS=99 ./stts

# Tylko 20 warstw na GPU (hybrydowe)
STTS_GPU_LAYERS=20 ./stts
```

Wymagania:
- NVIDIA GPU z CUDA Compute Capability 5.0+
- CUDA Toolkit (`nvcc` w PATH)
- cmake

## ğŸ”§ Text Normalization

STT moÅ¼e zwracaÄ‡ bÅ‚Ä™dny tekst (literÃ³wki, Åºle rozpoznane komendy). `TextNormalizer` automatycznie poprawia typowe bÅ‚Ä™dy:

| BÅ‚Ä…d STT | Korekta |
|----------|---------|
| `el es`, `l s` | `ls` |
| `eko` | `echo` |
| `kopi`, `kopiuj` | `cp` |
| `git pusz` | `git push` |
| `pip instal` | `pip install` |
| `sudo apt instal` | `sudo apt install` |

Normalizacja jest automatyczna i nie wymaga konfiguracji.

## âš¡ Optymalizacja szybkoÅ›ci

Dla maksymalnej szybkoÅ›ci:

```bash
# Fast start (pomija wolnÄ… detekcjÄ™ sprzÄ™tu)
STTS_FAST_START=1 ./stts

# UÅ¼yj mniejszego modelu
./stts --init whisper_cpp:tiny

# GPU + optymalne wÄ…tki (auto)
STTS_GPU_ENABLED=1 ./stts
```

Zmienne wydajnoÅ›ciowe:

| Zmienna | Opis | DomyÅ›lnie |
|---------|------|-----------|
| `STTS_GPU_ENABLED` | Wymusz GPU (1) lub CPU (0) | auto |
| `STTS_GPU_LAYERS` | Warstwy na GPU | 99 |
| `STTS_FAST_START` | Szybki start | 1 |
| `STTS_STREAM` | Strumieniuj output | 0 |

## ğŸš€ Instalacja

```bash
# 1. Pobierz
git clone https://github.com/wronai/stts
cd stts

# 2. Uruchom (wybierz wersjÄ™)
./stts           # Python 3.8+
./stts.mjs       # Node.js 18+

# 3. Opcjonalnie: zainstaluj globalnie
sudo ln -s $(pwd)/stts /usr/local/bin/stts
sudo ln -s $(pwd)/stts.mjs /usr/local/bin/stts-node
```

## ğŸ”„ Python vs Node.js

| Cecha | Python (`python/stts`) | Node.js (`nodejs/stts.mjs`) |
|-------|-------------------------|----------------------------|
| Wymagania | Python 3.8+ | Node.js 18+ |
| Windows | âœ… PeÅ‚ne | âš ï¸ CzÄ™Å›ciowe |
| Linux/macOS | âœ… | âœ… |
| ZaleÅ¼noÅ›ci | 0 (stdlib) | 0 (stdlib) |

### ZaleÅ¼noÅ›ci systemowe

```bash
# Linux (Ubuntu/Debian)
sudo apt install espeak alsa-utils sox

# macOS
brew install espeak sox

# Windows
# Python + espeak (lub uÅ¼yj system TTS)
```

## ğŸ“Š Wymagania sprzÄ™towe

### STT (Speech-to-Text)

| Provider | Min RAM | GPU | Offline | JakoÅ›Ä‡ | SzybkoÅ›Ä‡ |
|----------|---------|-----|---------|--------|----------|
| **whisper.cpp** | 1 GB | âŒ | âœ… | â­â­â­â­ | â­â­â­ |
| **faster-whisper** | 2 GB | âœ… (opt) | âœ… | â­â­â­â­â­ | â­â­â­â­ |
| **vosk** | 0.5 GB | âŒ | âœ… | â­â­â­ | â­â­â­â­â­ |
| **google** | 0.5 GB | âŒ | âŒ | â­â­â­â­ | â­â­â­ |

### Modele Whisper

| Model | RAM | VRAM | Rozmiar | JakoÅ›Ä‡ |
|-------|-----|------|---------|--------|
| tiny | 1 GB | - | 75 MB | â­â­ |
| base | 1 GB | - | 150 MB | â­â­â­ |
| small | 2 GB | - | 500 MB | â­â­â­â­ |
| medium | 4 GB | 2 GB | 1.5 GB | â­â­â­â­â­ |
| large | 8 GB | 4 GB | 3 GB | â­â­â­â­â­ |

### TTS (Text-to-Speech)

| Provider | Min RAM | JakoÅ›Ä‡ | Offline |
|----------|---------|--------|---------|
| **espeak** | 0.1 GB | â­â­ | âœ… |
| **piper** | 0.5 GB | â­â­â­â­â­ | âœ… |
| **system** | - | â­â­â­ | âœ… |

## ğŸ’» UÅ¼ycie

### Voice Shell (interaktywny)

```bash
./stts

ğŸ”Š stts> make build       # wpisz komendÄ™
ğŸ”Š stts>                  # ENTER = nagrywanie gÅ‚osu
ğŸ”Š stts> exit             # wyjÅ›cie
```

### Command Wrapper

```bash
# Uruchom komendÄ™ z gÅ‚osowym output
./stts make build
./stts python script.py
./stts kubectl get pods
./stts git status

# Ostatnia linijka output zostanie przeczytana na gÅ‚os
```

### STT placeholder (Python)

W trybie wrapper moÅ¼esz uÅ¼yÄ‡ `{STT}` jako placeholdera, ktÃ³ry zostanie zastÄ…piony transkryptem z mikrofonu:

```bash
STTS_NLP2CMD_ENABLED=1 ./stts nlp2cmd -r "{STT}"
```

### Pipeline (jednorazowe STT â†’ stdout, Python)

Tryb `--stt-once` wypisuje sam transkrypt na stdout (a logi na stderr), wiÄ™c nadaje siÄ™ do pipe:

```bash
./stts --stt-once | xargs -I{} nlp2cmd -r "{}"
```

**Strumieniowanie komend z git:** JeÅ›li chcesz zobaczyÄ‡ output `git` na bieÅ¼Ä…co (bez bufora), uÅ¼yj:

```bash
# Opcja 1: --dry-run + bash
./stts --dry-run git commit -m "{STT}" | bash

# Opcja 2: podstawienie argumentu (brak bufora)
git commit -m "$(./stts --stt-once)"
```

### Pipeline (TTS na koÅ„cu, Python)

JeÅ›li chcesz, Å¼eby dowolny pipeline koÅ„czyÅ‚ siÄ™ TTS (np. przeczytanie ostatniej niepustej linii), uÅ¼yj:

```bash
... | ./stts --tts-stdin
```

Uwaga: `{TTS}` nie jest wbudowanÄ… komendÄ… â€“ jeÅ›li chcesz mieÄ‡ skrÃ³t, ustaw alias w swoim shellu (np. `alias TTS='stts --tts-stdin'`).

Uwaga: aliasy (np. `TTS`) dziaÅ‚ajÄ… w Twoim shellu (bash/zsh), ale nie dziaÅ‚ajÄ… wewnÄ…trz promptu `stts>`.

PrzykÅ‚ad: zbuduj komendÄ™ i przeczytaj jÄ… na gÅ‚os (bez wykonania):

```bash
./stts --dry-run git commit -m "{STT}" | ./stts --tts-stdin
```

JeÅ›li koniecznie chcesz uÅ¼yÄ‡ aliasu, uruchom w normalnym shellu (nie w `stts>`), ewentualnie przez:

```bash
bash -c './stts --dry-run git commit -m "{STT}" | TTS'
```

### Makefile Integration

```makefile
# Dodaj do Makefile
%_voice:
	./stts make $*

# UÅ¼ycie:
# make build_voice
# make test_voice
```

## âš™ï¸ Konfiguracja

```bash
# Interaktywny setup
./stts --setup

# Jednolinijkowy setup (Python)
./stts --init whisper_cpp:tiny

# TTS w jednej linijce (Python)
./stts --tts-provider espeak --tts-voice pl

# Konfiguracja zapisywana w:
~/.config/stts-python/config.json
```

### PrzykÅ‚adowa konfiguracja

```json
{
  "stt_provider": "whisper_cpp",
  "stt_model": "small",
  "tts_provider": "piper",
  "tts_voice": "pl",
  "language": "pl",
  "timeout": 5,
  "auto_tts": true
}
```

## ğŸ”§ Providery

### STT: whisper.cpp (rekomendowany)

```bash
# Auto-instalacja przy setup
# Lub rÄ™cznie:
git clone https://github.com/ggerganov/whisper.cpp
cd whisper.cpp && make
```

#### whisper.cpp + GPU (CUDA)

JeÅ›li masz CUDA toolkit (`nvcc`) i chcesz przyspieszyÄ‡ transkrypcjÄ™ na GPU:

```bash
# podczas instalacji (setup)
STTS_GPU_ENABLED=1 ./stts --setup

# przy uruchomieniu: offload warstw na GPU
./stts --stt-gpu-layers 35
# albo przez env:
STTS_STT_GPU_LAYERS=35 ./stts
```

### STT: faster-whisper (GPU)

```bash
pip install faster-whisper
```

### STT: vosk (lekki, RPi)

```bash
pip install vosk
```

### TTS: piper (neural, rekomendowany)

```bash
# PrzykÅ‚ad (Python):
./stts --tts-provider piper --tts-voice pl_PL-gosia-medium

# albo podaj Å›cieÅ¼kÄ™ do modelu .onnx:
./stts --tts-provider piper --tts-voice ~/.config/stts-python/models/piper/pl_PL-gosia-medium.onnx

# Modele trzymane sÄ… w:
~/.config/stts-python/models/piper/
```

Wymagania:

- `piper` w `PATH` (binarka)
- model `*.onnx` w `~/.config/stts-python/models/piper/`
- odtwarzacz audio: `paplay` lub `aplay` lub `play`

Szybki check:

```bash
command -v piper
ls ~/.config/stts-python/models/piper/*.onnx
command -v paplay || command -v aplay || command -v play
```

**Automatyzacja (Python):**

```bash
# Auto-install piper + auto-download gÅ‚osu
./stts --install-piper
./stts --download-piper-voice pl_PL-gosia-medium

# Lub przez Makefile
make tts-setup-piper
```

### TTS: espeak (fallback)

```bash
sudo apt install espeak
```

## ğŸ“ Raspberry Pi

Dla RPi rekomendowane:
- **STT**: vosk (small-pl) lub whisper.cpp (tiny)
- **TTS**: espeak lub piper

```bash
# RPi setup
sudo apt install espeak alsa-utils
./stts --setup
# Wybierz: vosk + espeak
```

## ğŸ› Troubleshooting

### Brak mikrofonu

```bash
# SprawdÅº
arecord -l

# Zainstaluj
sudo apt install alsa-utils
```

### Brak dÅºwiÄ™ku TTS

```bash
# Diagnostyka (Python)
./stts --tts-test "Test TTS"

# JeÅ›li brak espeak/piper/player:
make tts-setup-espeak   # lub make tts-setup-piper
```

### Model nie pobiera siÄ™

```bash
# RÄ™czne pobranie whisper
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.bin
mv ggml-small.bin ~/.config/stts/models/whisper.cpp/
```

## ğŸ“ Struktura

```
stts/
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ stts
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ Makefile
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ tests/
â””â”€â”€ nodejs/
    â”œâ”€â”€ stts.mjs
    â”œâ”€â”€ README.md
    â”œâ”€â”€ Makefile
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ samples/
    â”œâ”€â”€ scripts/
    â””â”€â”€ tests/

~/.config/
â”œâ”€â”€ stts-python/   # config + models dla Python
â””â”€â”€ stts-nodejs/   # config + models dla Node.js
```

## ğŸ“š Dokumentacja

- **Python**: `python/README.md` â€“ szczegÃ³Å‚y TTS, piper, VAD, audio, CLI
- **Node.js**: `nodejs/README.md` â€“ szczegÃ³Å‚y ESM, Docker, CLI
- **Docs**: `docs/README.md` â€“ dodatkowe dokumenty (provider STT, testy E2E)
- **Examples**: `examples/README.md` â€“ gotowe skrypty E2E do uruchomienia
- **.env**: `.env.example` (root) + `python/.env.example` + `nodejs/.env.example`
- **Makefile**: `python/Makefile` â€“ targety `tts-setup-espeak`, `tts-setup-piper`

## ğŸ”— PowiÄ…zane projekty

### STT/TTS Engines
- **[whisper.cpp](https://github.com/ggerganov/whisper.cpp)** - High-performance inference of OpenAI's Whisper model
- **[faster-whisper](https://github.com/guillaumekint/faster-whisper)** - Faster Whisper transcription with CTranslate2
- **[vosk](https://github.com/alphacep/vosk-api)** - Offline speech recognition API
- **[piper](https://github.com/rhasspy/piper)** - Fast, local neural text-to-speech system
- **[espeak](https://espeak.sourceforge.io/)** - Compact open source speech synthesizer

### CLI Tools
- **[nlp2cmd](https://github.com/wronai/nlp2cmd)** - Natural Language to Command converter
- **[whisper-cli](https://github.com/ahmedkheir/whisper-cli)** - Command-line interface for Whisper

### Audio Libraries
- **[pyaudio](https://github.com/pyaudio/pyaudio)** - Python bindings for PortAudio
- **[sox](https://sox.sourceforge.io/)** - Sound eXchange - universal sound processing utility

## ğŸ“œ Licencja

Apache 2.0
